{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7b5f1-0928-4bde-bfcb-abc1a9583fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89484bb2-974c-40fc-b3d9-39609ab8dbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n",
      "None\n",
      "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
      "0      T     2     8      3       5      1     8    13      0      6      6   \n",
      "1      I     5    12      3       7      2    10     5      5      4     13   \n",
      "2      D     4    11      6       8      6    10     6      2      6     10   \n",
      "3      N     7    11      6       6      3     5     9      4      6      4   \n",
      "4      G     2     1      3       1      1     8     6      6      6      6   \n",
      "\n",
      "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
      "0      10       8      0       8      0       8  \n",
      "1       3       9      2       8      4      10  \n",
      "2       3       7      3       7      3       9  \n",
      "3       4      10      6      10      2       8  \n",
      "4       5       9      1       7      5      10  \n",
      "letter    0\n",
      "xbox      0\n",
      "ybox      0\n",
      "width     0\n",
      "height    0\n",
      "onpix     0\n",
      "xbar      0\n",
      "ybar      0\n",
      "x2bar     0\n",
      "y2bar     0\n",
      "xybar     0\n",
      "x2ybar    0\n",
      "xy2bar    0\n",
      "xedge     0\n",
      "xedgey    0\n",
      "yedge     0\n",
      "yedgex    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(r\"D:\\HI448116_Santosh_Karpe\\FY25\\DOCS\\III\\Ass\\ASA - SK\\Alphabets_data.csv\")\n",
    "\n",
    "# Show basic information about the dataset\n",
    "print(data.info())\n",
    "\n",
    "# Check the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df65acf-540c-4a00-be5c-2d3f8cbf26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ec0c095-1631-4e95-b125-4dd623cf304d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
      "0          T     2     8      3       5      1     8    13      0      6   \n",
      "1          I     5    12      3       7      2    10     5      5      4   \n",
      "2          D     4    11      6       8      6    10     6      2      6   \n",
      "3          N     7    11      6       6      3     5     9      4      6   \n",
      "4          G     2     1      3       1      1     8     6      6      6   \n",
      "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
      "19995      D     2     2      3       3      2     7     7      7      6   \n",
      "19996      C     7    10      8       8      4     4     8      6      9   \n",
      "19997      T     6     9      6       7      5     6    11      3      7   \n",
      "19998      S     2     3      4       2      1     8     7      2      6   \n",
      "19999      A     4     9      6       6      2     9     5      3      1   \n",
      "\n",
      "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
      "0          6      10       8      0       8      0       8  \n",
      "1         13       3       9      2       8      4      10  \n",
      "2         10       3       7      3       7      3       9  \n",
      "3          4       4      10      6      10      2       8  \n",
      "4          6       5       9      1       7      5      10  \n",
      "...      ...     ...     ...    ...     ...    ...     ...  \n",
      "19995      6       6       4      2       8      3       7  \n",
      "19996     12       9      13      2       9      3       7  \n",
      "19997     11       9       5      2      12      2       4  \n",
      "19998     10       6       8      1       9      5       8  \n",
      "19999      8       1       8      2       7      2       8  \n",
      "\n",
      "[20000 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['letter'])\n",
    "y = data['xbox']\n",
    "\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "print(data)\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63c4a7-2161-4405-924f-db0bd9b7ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Implementation\n",
    "#Building a Basic ANN Model\n",
    "#Create a simple ANN model using Keras/TensorFlow or PyTorch. \n",
    "#The model will have at least one hidden layer with ReLU activation and an output layer with a softmax activation function to handle multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b39725e-e93b-45f5-ae80-a585cba7597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a89966b8-dab4-48a5-9bd6-202f125461df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_train before filtering: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Epoch 1/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5084 - loss: 1.4678 - val_accuracy: 0.9072 - val_loss: 0.4012\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9336 - loss: 0.3068 - val_accuracy: 0.9703 - val_loss: 0.1281\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9793 - loss: 0.0962 - val_accuracy: 0.9877 - val_loss: 0.0620\n",
      "Epoch 4/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9895 - loss: 0.0511 - val_accuracy: 0.9945 - val_loss: 0.0402\n",
      "Epoch 5/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0369 - val_accuracy: 0.9965 - val_loss: 0.0245\n",
      "Epoch 6/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0224 - val_accuracy: 0.9970 - val_loss: 0.0176\n",
      "Epoch 7/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0150 - val_accuracy: 0.9967 - val_loss: 0.0145\n",
      "Epoch 8/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0102 - val_accuracy: 0.9977 - val_loss: 0.0105\n",
      "Epoch 9/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0114 - val_accuracy: 0.9977 - val_loss: 0.0089\n",
      "Epoch 10/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0081 - val_accuracy: 0.9975 - val_loss: 0.0098\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0098\n",
      "Test loss: 0.009828943759202957, Test accuracy: 0.9975000023841858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Split the dataset into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the unique values in y_train and y_test\n",
    "print(f\"Unique values in y_train before filtering: {np.unique(y_train)}\")\n",
    "\n",
    "# One-hot encode labels for 16 classes (if you have 16 unique values)\n",
    "y_train = to_categorical(y_train, num_classes=16)\n",
    "y_test = to_categorical(y_test, num_classes=16)\n",
    "\n",
    "# Build the model with 16 output units (for 16 classes)\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1], activation='relu'),  # Input layer + hidden layer 1\n",
    "    Dense(64, activation='relu'),  # Hidden layer 2\n",
    "    Dense(16, activation='softmax')  # Output layer (for 16 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14a3aefb-18f6-4ee5-9946-944ea06283dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0098\n",
      "Test accuracy: 0.9975000023841858\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6216ff-53b6-4ff4-bd8a-61c4b100a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning\n",
    "#Hyperparameter Tuning Strategy\n",
    "#Hyperparameters that influence model performance include:\n",
    "#Number of hidden layers and neurons per layer.\n",
    "#Activation functions (e.g., ReLU, tanh, sigmoid).\n",
    "#Learning rate.\n",
    "#Optimizer (e.g., Adam, SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82f62dbe-f27a-4ddf-8c59-268b130c0086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9917500019073486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# Define a custom model wrapper class to integrate with scikit-learn\n",
    "class KerasModelWrapper(BaseEstimator):\n",
    "    def __init__(self, epochs=10, batch_size=32):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(16, activation='softmax')  # 16 classes\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = self.build_model()\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        loss, accuracy = self.model.evaluate(X, y, verbose=0)\n",
    "        return accuracy\n",
    "\n",
    "# Example usage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "y_train = to_categorical(y_train, num_classes=16)\n",
    "y_test = to_categorical(y_test, num_classes=16)\n",
    "\n",
    "# Create model wrapper\n",
    "keras_model = KerasModelWrapper(epochs=10, batch_size=32)\n",
    "\n",
    "# Fit the model\n",
    "keras_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = keras_model.score(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c1ed6-7a60-45c1-a0be-317bdb1f43ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "#Evaluation Metrics\n",
    "#Use metrics such as accuracy, precision, recall, and F1-score to evaluate the model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d968fcf-e7c3-4325-b951-c6a90ef2f552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       1.00      1.00      1.00       240\n",
      "           2       1.00      1.00      1.00       610\n",
      "           3       1.00      1.00      1.00       843\n",
      "           4       1.00      1.00      1.00       871\n",
      "           5       1.00      1.00      1.00       633\n",
      "           6       1.00      1.00      1.00       382\n",
      "           7       1.00      1.00      1.00       190\n",
      "           8       0.99      1.00      1.00       106\n",
      "           9       1.00      0.98      0.99        57\n",
      "          10       1.00      0.85      0.92        26\n",
      "          11       0.67      0.73      0.70        11\n",
      "          12       0.50      1.00      0.67         4\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       0.81      0.84      0.82      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hi448116\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\hi448116\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\hi448116\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\hi448116\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\hi448116\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\hi448116\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis=1)  # Convert one-hot encoding back to label\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test.argmax(axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0073efd-01f3-47b1-a106-d134fa5b6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discussion of Performance\n",
    "#1) Compare the model's performance using default hyperparameters versus the performance using the tuned hyperparameters.\n",
    "#2) Discuss how different hyperparameters, such as the number of neurons, activation functions, and optimizer, influenced the model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
