{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7b5f1-0928-4bde-bfcb-abc1a9583fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing, Feature Engineering, and Feature Selection: Adult Income Prediction Dataset\n",
    "# The dataset, often referred to as the \"Adult\" dataset,\n",
    "# is a popular dataset in machine learning that contains census data for predicting whether a person earns more than $50K per year based on attributes like age, education, occupation, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8f5720-9bf7-4ddd-9c6a-f520bc744456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education_num   32561 non-null  int64 \n",
      " 5   marital_status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital_gain    32561 non-null  int64 \n",
      " 11  capital_loss    32561 non-null  int64 \n",
      " 12  hours_per_week  32561 non-null  int64 \n",
      " 13  native_country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n",
      "None\n",
      "                age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
      "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
      "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
      "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
      "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
      "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
      "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
      "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
      "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
      "\n",
      "       hours_per_week  \n",
      "count    32561.000000  \n",
      "mean        40.437456  \n",
      "std         12.347429  \n",
      "min          1.000000  \n",
      "25%         40.000000  \n",
      "50%         40.000000  \n",
      "75%         45.000000  \n",
      "max         99.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'D:\\HI448116_Santosh_Karpe\\FY25\\DOCS\\III\\Ass\\ASA - SK\\adult_with_headers.csv')\n",
    "\n",
    "# Basic data exploration\n",
    "print(df.head())  # Display first 5 rows\n",
    "print(df.info())  # Data types and non-null count\n",
    "print(df.describe())  # Summary statistics for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ccd7f7-90e9-4b7b-9708-2e5116785f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education_num     0\n",
      "marital_status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital_gain      0\n",
      "capital_loss      0\n",
      "hours_per_week    0\n",
      "native_country    0\n",
      "income            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert [[' State-gov' ' Self-emp-not-inc' ' Private' ... ' Private' ' Private'\n  ' Self-emp-inc']\n [' Bachelors' ' Bachelors' ' HS-grad' ... ' HS-grad' ' HS-grad'\n  ' HS-grad']\n [' Never-married' ' Married-civ-spouse' ' Divorced' ... ' Widowed'\n  ' Never-married' ' Married-civ-spouse']\n ...\n [' Male' ' Male' ' Male' ... ' Female' ' Male' ' Female']\n [' United-States' ' United-States' ' United-States' ... ' United-States'\n  ' United-States' ' United-States']\n [' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' <=50K' ' >50K']] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Impute missing values (example: median imputation for numerical columns)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df\u001b[38;5;241m.\u001b[39mfillna(df\u001b[38;5;241m.\u001b[39mmedian(), inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Or, drop rows with missing values\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:11706\u001b[0m, in \u001b[0;36mDataFrame.median\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11698\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(\n\u001b[0;32m  11700\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11704\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11705\u001b[0m ):\n\u001b[1;32m> 11706\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmedian(axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  11707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11708\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:12431\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(\n\u001b[0;32m  12425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12426\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12429\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmedian, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12433\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  12379\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:11562\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11558\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11560\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11561\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11562\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  11563\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:1500\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1498\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1500\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[0;32m   1501\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1503\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\blocks.py:404\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    407\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:11481\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py:787\u001b[0m, in \u001b[0;36mnanmedian\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    785\u001b[0m     inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values)\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 787\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    789\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert [[' State-gov' ' Self-emp-not-inc' ' Private' ... ' Private' ' Private'\n  ' Self-emp-inc']\n [' Bachelors' ' Bachelors' ' HS-grad' ... ' HS-grad' ' HS-grad'\n  ' HS-grad']\n [' Never-married' ' Married-civ-spouse' ' Divorced' ... ' Widowed'\n  ' Never-married' ' Married-civ-spouse']\n ...\n [' Male' ' Male' ' Male' ... ' Female' ' Male' ' Female']\n [' United-States' ' United-States' ' United-States' ... ' United-States'\n  ' United-States' ' United-States']\n [' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' <=50K' ' >50K']] to numeric"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Impute missing values (example: median imputation for numerical columns)\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Or, drop rows with missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8cb7d6-41e6-4116-bd6c-e2d178ea63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling Techniques\n",
    "#To scale numerical features, we’ll apply Standard Scaling and Min-Max Scaling.\n",
    "#Scaling ensures that features with larger ranges do not dominate models that rely on distance-based metrics (e.g., KNN, SVM).\n",
    "#Standard Scaling\n",
    "#Standard scaling standardizes the data by subtracting the mean and dividing by the standard deviation. \n",
    "#This centers the data around 0 with a unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd389c46-43ee-4a0b-8897-c7bf76e2e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled_standard = df.copy()\n",
    "df_scaled_standard[['age', 'education_num']] = scaler.fit_transform(df[['age', 'education_num']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9431e-15ce-4f3d-941c-253f0d6222b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaling\n",
    "# Min-max scaling rescales features to a range of [0, 1], making it ideal for algorithms that require data within this range (e.g., neural networks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e075ae-cbc7-4f92-810d-0c3cb06b49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled_minmax = df.copy()\n",
    "df_scaled_minmax[['age', 'education_num']] = scaler.fit_transform(df[['age', 'education_num']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6272be4-cbf0-4f8f-b182-2dfcf5e0a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Techniques\n",
    "#One-Hot Encoding for Categorical Variables with Less than 5 Categories\n",
    "#One-hot encoding converts categorical variables into binary (0 or 1) features. \n",
    "#It is useful for categorical variables that have fewer unique categories (less than 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31a7dd6a-608c-499d-81d9-f0024c13394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['workclass', 'education', ], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d84690-2d91-4b59-863a-ff78eda74f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding for Categorical Variables with More than 5 Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80b33a1e-06aa-476e-952e-9f33fcaba555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['occupation_encoded'] = le.fit_transform(df['occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641b6205-9cd0-408d-ae0c-bb80a4a773f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Feature Engineering\n",
    "#Creating New Features\n",
    "#Feature engineering involves creating new features that could provide valuable information to the model.\n",
    "#Feature 1: Age Group Create a feature to categorize the individuals into age groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68078f74-77be-4a75-a70d-2da34949dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_group'] = pd.cut(df['age'], bins=[0, 18, 30, 40, 50, 60, 100], labels=['<18', '18-30', '30-40', '40-50', '50-60', '60+'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f4a1a-7903-4959-8b72-d697fdc9128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature 2: Work Hours Over 40 Create a feature to indicate if the person works more than 40 hours per week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98fee8a0-c83c-4110-811c-652ab880ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['work_over_40'] = df['hours_per_week'].apply(lambda x: 1 if x > 40 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a094f7b-1c55-499b-8c19-74a70cffecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log Transformation of Skewed Features\n",
    "#Skewed numerical features (like income) can be transformed using a log transformation to normalize the data distribution, \n",
    "#which can help improve model performance, especially for linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93628efa-0cea-49b8-a4f4-5929af69f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Apply log transformation\n",
    "df['log_hours_per_week'] = np.log1p(df['hours_per_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06cf72-725a-4b28-a88d-33f536a413f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "#Outlier Detection with Isolation Forest\n",
    "#Outliers can severely affect model performance, especially with distance-based models. \n",
    "#One technique to detect and remove outliers is using the Isolation Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7845b5f-5f59-4960-baf1-c2ad07f7cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Apply Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.05)\n",
    "outliers = iso_forest.fit_predict(df[['age', 'hours_per_week']])\n",
    "\n",
    "# Mark outliers with -1 and inliers with 1\n",
    "df['outlier'] = outliers\n",
    "df_no_outliers = df[df['outlier'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277bded-e2d4-4030-96a8-706ce31e8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PPS (Predictive Power Score)\n",
    "#The PPS score quantifies the predictive power of a feature with respect to the target variable.\n",
    "#It helps identify features that have the most influence on the target and can guide feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844db768-8d9b-4d89-8e30-1f3ab18c4e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppscore as pps\n",
    "\n",
    "# Compute PPS matrix\n",
    "pps_matrix = pps.matrix(df)\n",
    "print(pps_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
